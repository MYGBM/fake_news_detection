
import re
class Preprocess:
    def __init__(self) -> None:
        self.normalization_rules = [
            (re.compile(r"[áˆáˆƒáŠ»áˆ“áŠ€áŠƒ]"), "áˆ€"),
            (re.compile(r"[áˆ‘áŠáŠ¹]"), "áˆ"),
            (re.compile(r"[áˆ’áŠ‚áŠº]"), "áˆ‚"),
            (re.compile(r"[áˆ”áŠ„áŠ¼]"), "áˆ„"),
            (re.compile(r"[áˆ•áŠ…áŠ½]"), "áˆ…"),
            (re.compile(r"[áˆ–áŠ†áŠ¾]"), "áˆ†"),
            (re.compile(r"[áŠ‡]"), "áˆ—"),
            (re.compile(r"[áˆ ]"), "áˆ°"),
            (re.compile(r"[áˆ¡]"), "áˆ±"),
            (re.compile(r"[áˆ¢]"), "áˆ²"),
            (re.compile(r"[áˆ£]"), "áˆ³"),
            (re.compile(r"[áˆ¤]"), "áˆ´"),
            (re.compile(r"[áˆ¥]"), "áˆµ"),
            (re.compile(r"[áˆ¦]"), "áˆ¶"),
            (re.compile(r"[áˆ§]"), "áˆ·"),
            (re.compile(r"[áŠ£á‹á‹“]"), "áŠ "),
            (re.compile(r"[á‹‘]"), "áŠ¡"),
            (re.compile(r"[á‹’]"), "áŠ¢"),
            (re.compile(r"[á‹”]"), "áŠ¤"),
            (re.compile(r"[á‹•]"), "áŠ¥"),
            (re.compile(r"[á‹–]"), "áŠ¦"),
            (re.compile(r"[áŒ¸]"), "á€"),
            (re.compile(r"[áŒ¹]"), "á"),
            (re.compile(r"[áŒº]"), "á‚"),
            (re.compile(r"[áŒ»]"), "áƒ"),
            (re.compile(r"[áŒ¼]"), "á„"),
            (re.compile(r"[áŒ½]"), "á…"),
            (re.compile(r"[áŒ¾]"), "á†"),
            (re.compile(r"(áˆ‰[á‹‹áŠ ])"), "áˆ"),
            (re.compile(r"(áˆ‘[á‹‹áŠ ])"), "áˆ—"),
            (re.compile(r"(áˆ™[á‹‹áŠ ])"), "áˆŸ"),
            (re.compile(r"(á‰±[á‹‹áŠ ])"), "á‰·"),
            (re.compile(r"(áˆ©[á‹‹áŠ ])"), "áˆ¯"),
            (re.compile(r"(áˆ±[á‹‹áŠ ])"), "áˆ·"),
            (re.compile(r"(áˆ¹[á‹‹áŠ ])"), "áˆ¿"),
            (re.compile(r"(á‰[á‹‹áŠ ])"), "á‰‹"),
            (re.compile(r"(á‰¡[á‹‹áŠ ])"), "á‰§"),
            (re.compile(r"(á‰¹[á‹‹áŠ ])"), "á‰¿"),
            (re.compile(r"(áˆ[á‹‹áŠ ])"), "áŠ‹"),
            (re.compile(r"(áŠ‘[á‹‹áŠ ])"), "áŠ—"),
            (re.compile(r"(áŠ™[á‹‹áŠ ])"), "áŠŸ"),
            (re.compile(r"(áŠ©[á‹‹áŠ ])"), "áŠ³"),
            (re.compile(r"(á‹™[á‹‹áŠ ])"), "á‹Ÿ"),
            (re.compile(r"(áŒ‰[á‹‹áŠ ])"), "áŒ“"),
            (re.compile(r"(á‹°[á‹‹áŠ ])"), "á‹·"),
            (re.compile(r"(áŒ¡[á‹‹áŠ ])"), "áŒ§"),
            (re.compile(r"(áŒ©[á‹‹áŠ ])"), "áŒ¯"),
            (re.compile(r"(áŒ¹[á‹‹áŠ ])"), "áŒ¿"),
            (re.compile(r"(á‰[á‹‹áŠ ])"), "á"),
        ]
    

    def data_profile(self, dataframe, column_name: str) -> dict:  
        # Key checks
        checks = {
            "URLs": r"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+",
            "English words/digits": r"[a-zA-Z]|[0-9]+",
            "Amharic Geez numbers": r"[á©áªá«á¬á­á®á¯á°á±á²á³á´áµá¶á·á¸á¹áºá»]",
            "Special characters/punctuation": r"[^\w\s]",
            "Emojis": r"[\U00010000-\U0010ffff]",
            "Extra spaces": r"\s{2,}",
            "HTML tags": r"<[^>]*>",
            "Elongated words": r"(.)\1{2,}",
        }
        
        # Dictionary to accumulate counts
        total_counts = {key: 0 for key in checks}
        total_counts["Leading/trailing spaces"] = 0
        # Iterate over each row in the specified column
        for text in dataframe[column_name]:
            # Convert text to string (handles NaN or non-string data)
            text = str(text)     
            for key, pattern in checks.items():
                matches = re.findall(pattern, text)
                total_counts[key] += len(matches)  # Add the count of matches for this row
            
            # Check leading/trailing spaces
            stripped_text = text.strip()
            if stripped_text != text:
                total_counts["Leading/trailing spaces"] += 1
    

        return total_counts


    def preprocess_data(self, text: str) -> str:
        text = re.sub(r"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+", "", text)
        # Remove html tags
        text = re.sub(r'<[^>]*>', '', text)
        # Remove English words and digits
        text = re.sub(r"[a-zA-Z]|[0-9]+", "", text)
        # Remove Amharic Geez numbers
        text = re.sub(r"[á©áªá«á¬á­á®á¯á°á±á²á³á´áµá¶á·á¸á¹áºá»]", "", text)
        # Remove special characters and punctuation
        text = re.sub(r"[^\w\s]|_|-", "", text)
        # Remove emojis, and bold/italics, etc extra style texts which are neither special characters or english letters  like ğ—¢ğ—¿ğ—¼ğ—ºğ—¼ğ—£ğ—¿ğ—¼ğ˜ğ—²ğ˜€ğ˜ğ˜€ğ—¯ğ—¼ğ—¹ğ—±ğ‘–ğ‘¡ğ‘ğ‘™ğ‘–ğ‘
        text = re.sub(r"[\U00010000-\U0010ffff]", "", text)
        # Remove elongated words (2+ occurrences)
        text = re.sub(r'(.)\1{2,}', r'\1\1', text)
        # Remove extra spaces and leading/trailing spaces
        text = re.sub(r"\s{2,}", " ", text)
        for pattern, replacement in self.normalization_rules:
            text = pattern.sub(replacement, text)
        return text.strip()
